{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews = pd.read_csv('train_pwd_required/train.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews['CleanReview']=Reviews['ReviewText'].astype(str)\n",
    "Reviews['CleanReview']=Reviews['CleanReview'].str.replace('[^a-zA-Z\\s]','').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return words count\n",
    "def review_words(review_row):\n",
    "    words = review_row.split()\n",
    "    return( len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store review words count in a separate column\n",
    "Reviews['WordCount']=Reviews['CleanReview'].apply(lambda x: review_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum-length reviews: 0\n",
      "Maximum review length: 5986\n"
     ]
    }
   ],
   "source": [
    "##reviews max and min length\n",
    "print(\"Minimum-length reviews: {}\".format(min(Reviews['WordCount'])))\n",
    "print(\"Maximum review length: {}\".format(max(Reviews['WordCount'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=100\n",
    "#keep reviews with non zero max length 100 words \n",
    "ReviewsN=Reviews.loc[Reviews['WordCount'] <= n_steps]\n",
    "ReviewsN=ReviewsN.loc[Reviews['WordCount'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ReviewText  CleanReview  WordCount\n",
      "Rating                                    \n",
      "1            66247        66331      66331\n",
      "2            44299        44366      44366\n",
      "3            79714        79794      79794\n",
      "4           200354       200600     200600\n",
      "5           721318       721900     721900\n"
     ]
    }
   ],
   "source": [
    "print(ReviewsN.groupby('Rating').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "#Random Selection of specific reviews by group\n",
    "ReviewsNo = 5000  #30000 for scores 1,4,5 and 21000 for score 2 since is less than 30000\n",
    "Reviews5 = ReviewsN.loc[ReviewsN['Rating'] == 5].sample(ReviewsNo)\n",
    "Reviews4 = ReviewsN.loc[ReviewsN['Rating'] == 4].sample(ReviewsNo)\n",
    "Reviews2 = ReviewsN.loc[ReviewsN['Rating'] == 2].sample(5000)\n",
    "Reviews1 = ReviewsN.loc[ReviewsN['Rating'] == 1].sample(ReviewsNo)\n",
    "\n",
    "ReviewsF = Reviews1.append([Reviews2, Reviews4, Reviews5])\n",
    "print(len(ReviewsF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ReviewText  CleanReview  WordCount\n",
      "Rating                                    \n",
      "1             4991         5000       5000\n",
      "2             4991         5000       5000\n",
      "4             4995         5000       5000\n",
      "5             4993         5000       5000\n"
     ]
    }
   ],
   "source": [
    "TotalReviewsNo = 20000\n",
    "ReviewsF=ReviewsF.sample(TotalReviewsNo)\n",
    "\n",
    "#Reviews Random group by Score\n",
    "print(ReviewsF.groupby('Rating').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ' '.join(ReviewsF['CleanReview'])\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29721 unique words tokens.\n"
     ]
    }
   ],
   "source": [
    "word_freq = nltk.FreqDist(words)\n",
    "print (\"Found %d unique words tokens.\" % len(word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "for each in ReviewsF['CleanReview']:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in each.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = n_steps\n",
    "features = np.zeros((len(reviews_ints), seq_len), dtype=int)\n",
    "\n",
    "for i, row in enumerate(reviews_ints):\n",
    "    if len(row)>0: \n",
    "        features[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "<class 'numpy.ndarray'>\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0  2346   508 11791\n",
      "  2347   238     3   104     6  4052   215   513    83    43    14     4\n",
      "  8756  2400  2575     1    63    17    89     4   900     6 11792  7244\n",
      "    39  1120     6  5700]\n",
      "100\n",
      "[2346, 508, 11791, 2347, 238, 3, 104, 6, 4052, 215, 513, 83, 43, 14, 4, 8756, 2400, 2575, 1, 63, 17, 89, 4, 900, 6, 11792, 7244, 39, 1120, 6, 5700]\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "#print test row\n",
    "print(len(features))\n",
    "print(type(features))\n",
    "print(features[10])\n",
    "print(len(features[10]))\n",
    "print(reviews_ints[10])\n",
    "print(len(reviews_ints[10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert score to binary - values 1-2 means negative(0), values 4,5 means positive(1)\n",
    "ReviewsF['Score_label']=ReviewsF['Rating'].apply(lambda x: 0 if x < 3 else 1)\n",
    "#labels set as array\n",
    "labels=np.array(ReviewsF['Score_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(18000, 100) \n",
      "Validation set: \t(1000, 100) \n",
      "Test set: \t\t(1000, 100)\n",
      "label set: \t\t(18000,) \n",
      "Validation label set: \t(1000,) \n",
      "Test label set: \t\t(1000,)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.9\n",
    "\n",
    "split_index = int(split_frac * len(features))\n",
    "\n",
    "train_x, val_x = features[:split_index], features[split_index:] \n",
    "train_y, val_y = labels[:split_index], labels[split_index:]\n",
    "\n",
    "split_frac = 0.5\n",
    "split_index = int(split_frac * len(val_x))\n",
    "\n",
    "val_x, test_x = val_x[:split_index], val_x[split_index:]\n",
    "val_y, test_y = val_y[:split_index], val_y[split_index:]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
    "print(\"label set: \\t\\t{}\".format(train_y.shape), \n",
    "      \"\\nValidation label set: \\t{}\".format(val_y.shape),\n",
    "      \"\\nTest label set: \\t\\t{}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_size = 256\n",
    "lstm_layers = 2\n",
    "batch_size = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(vocab_to_int) + 1 # Add 1 for 0 added to vocab\n",
    "\n",
    "#Create the graph object\n",
    "tf.reset_default_graph()\n",
    "with tf.name_scope('inputs'):\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name=\"inputs\")\n",
    "    labels_ = tf.placeholder(tf.int32, [None, None], name=\"labels\") #labels_ needs to be two-dimensional to work with some functions later\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\") #keep_prob is a scalar (a 0-dimensional tensor), we shouldn't provide a size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # Size of the embedding vectors (number of units in the embedding layer)\n",
    "\n",
    "with tf.name_scope(\"Embeddings\"):\n",
    "    embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell():\n",
    "    # Our basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size, reuse=tf.get_variable_scope().reuse)\n",
    "    # Add dropout to the cell\n",
    "    return tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "\n",
    "with tf.name_scope(\"RNN_layers\"):\n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(lstm_layers)])\n",
    "    \n",
    "    #[drop] * lstm_layers creates a list of cells (drop) that is lstm_layers long \n",
    "    #The MultiRNNCell wrapper builds this into multiple layers of RNN cells, one for each cell in the list\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"RNN_forward\"):\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed, initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('predictions'):\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "with tf.name_scope('cost'):\n",
    "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add a few nodes to calculate the accuracy which we'll use in the validation pass\n",
    "with tf.name_scope('validation'):\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Batching######\n",
    "#This is a simple function for returning batches from our data. \n",
    "#First it removes data such that we only have full batches. \n",
    "#Then it iterates through the x and y arrays and returns slices out of those arrays with size [batch_size].\n",
    "\n",
    "def get_batches(x, y, batch_size):\n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Training and validation in batches\n",
    "###Once the graph is defined, training can be done in batches based on the batch_size hyper parameter.        \n",
    "\n",
    "n_epochs = 1\n",
    "#batches = len(train_x)//batch_size\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Cost=0.258546889 Train accuracy=0.594388902 Val accuracy=0.777000010\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# with graph.as_default():\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) #Initialize all variables\n",
    "    #matrices to store values for charts\n",
    "    epochs = []  #Iterations\n",
    "    costs = []  #Loss\n",
    "    tr_acc = []  #Training Accuracy\n",
    "    val_acc = [] #Val Accuracy\n",
    "    b_cost= [] #Training Bach Cost\n",
    "    b_tr_acc = [] #Training Bach Accuracy\n",
    "    b_te_acc = [] #Val Bach Accuracy\n",
    "       \n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "\n",
    "            batch_acc, loss, state, _ = sess.run([accuracy, cost, final_state, optimizer], feed_dict=feed)\n",
    "            b_tr_acc.append(batch_acc)\n",
    "            b_cost.append(loss)\n",
    "            \n",
    "        if (e+1) % display_step == 0:\n",
    "        #calculate val acc\n",
    "            val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "            for x, y in get_batches(val_x, val_y, batch_size):\n",
    "                feed = {inputs_: x,\n",
    "                        labels_: y[:, None],\n",
    "                        keep_prob: 1,\n",
    "                        initial_state: val_state}\n",
    "                batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                b_te_acc.append(batch_acc)\n",
    "\n",
    "            print(\"Epoch: \"+str('%04d' % (e+1))+\" Cost=\"+\"{:.9f}\".format(np.mean(b_cost))+\n",
    "                  \" Train accuracy=\"+\"{:.9f}\".format(np.mean(b_tr_acc))+\n",
    "                  \" Val accuracy=\"+\"{:.9f}\".format(np.mean(b_te_acc)))\n",
    "            # add results to matrices at the end of each epoch\n",
    "            epochs.append(e+1)\n",
    "            tr_acc.append(np.mean(b_tr_acc))\n",
    "            val_acc.append(np.mean(b_te_acc))\n",
    "            costs.append(np.mean(b_cost))\n",
    "        \n",
    "        saver.save(sess, './sentiment_model.ckpt')\n",
    "  \n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20c0508ae80>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################################################################\n",
    "##################### Charts for learning curve and train cost  #####################################\n",
    "#####################################################################################################\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20, 6)\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig1 = plt.figure()\n",
    "\n",
    "ax = fig1.add_subplot(121)\n",
    "ax.clear()\n",
    "\n",
    "ax.set_title(\"Learning curve\")\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.plot(epochs, tr_acc,     'o-', color=\"g\", label=\"Train Accuracy\")\n",
    "ax.plot(epochs, val_acc,   'o-', color=\"r\", label=\"Test Accuracy\")\n",
    "\n",
    "ax2 = fig1.add_subplot(122)\n",
    "ax2.clear()\n",
    "\n",
    "ax2.set_title(\"Train cost\")\n",
    "ax2.set_xlabel('Iterations')\n",
    "ax2.set_ylabel('Cost')\n",
    "ax2.set_ylim(ymin=0)\n",
    "ax2.plot(epochs, costs, 'o-', color=\"r\", label=\"Train cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./sentiment_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################\n",
    "#####################   Testing             #########################################################\n",
    "#####################################################################################################    \n",
    "    \n",
    "test_pred = []\n",
    "test_acc = []\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './sentiment_model.ckpt')\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: x,\n",
    "                labels_: y[:, None],\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "        \n",
    "        prediction = tf.cast(tf.round(predictions),tf.int32)\n",
    "        prediction = sess.run(prediction,feed_dict=feed)\n",
    "        test_pred.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test1_generic_reviews.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"')\n",
    "df_test = df_test[~df_test['ReviewText'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 431 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_validation_set1 = pd.read_csv('test1_generic_reviews.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"', index_col=0)\n",
    "df_validation_set2 = pd.read_csv('testB_dell_reviews.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_set1['ReviewText'].fillna('', inplace=True)\n",
    "df_validation_set2['ReviewText'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1 = clf.predict(X_validation1)\n",
    "predicted2 = clf.predict(X_validation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yesterday I spent over an hour playing with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I was looking for a light weight cable to go f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>There appears to be an engineering flaw in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>They aren't wide-angle as advertised. They don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The angled picture of the ends of this cable m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         ReviewText\n",
       "0   0  Yesterday I spent over an hour playing with a ...\n",
       "1   1  I was looking for a light weight cable to go f...\n",
       "2   2  There appears to be an engineering flaw in the...\n",
       "3   3  They aren't wide-angle as advertised. They don...\n",
       "4   4  The angled picture of the ends of this cable m..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.759\n",
      "Confusion Matrix\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################\n",
    "#####################   Results             #########################################################\n",
    "#####################################################################################################    \n",
    "\n",
    "##############Confusion Matrix######################    \n",
    "test_pred_flat = (np.array(test_pred)).flatten()\n",
    "#y_act = pd.Series(test_y, name='ReviewText')\n",
    "#y_pred = pd.Series(df_test, name='ReviewText')\n",
    "#df_confusion = pd.crosstab( y_pred, margins=True)\n",
    "\n",
    "print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))  \n",
    "print(\"Confusion Matrix\")\n",
    "print(\"----------------\")\n",
    "#print(df_confusion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagorb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "##############Review Text for Testing Results######################    \n",
    "#Take Reviews for test set\n",
    "start_idx = len(df_test) \n",
    "end_idx = start_idx + len(test_pred_flat)\n",
    "ReviewsTest=df_test.iloc[start_idx:end_idx]\n",
    "#Add Predicted Sentiment in a new column\n",
    "ReviewsTest['Predicted_Sentiment']= test_pred_flat\n",
    "\n",
    "#Examples of False Negative Results\n",
    "#ReviewsTest[(ReviewsTest['Score_label'] == 1) & (ReviewsTest['Predicted_Sentiment'] == 0 )].iloc[1:10]    \n",
    "#Examples of False Positive Results\n",
    "#ReviewsTest[(ReviewsTest['Score_label'] == 0) & (ReviewsTest['Predicted_Sentiment'] == 1 )].iloc[1:10]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagorb\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>Rating</th>\n",
       "      <th>CleanReview</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>Score_label</th>\n",
       "      <th>Predicted_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643867</th>\n",
       "      <td>I ordered these mainly because my wife was com...</td>\n",
       "      <td>1</td>\n",
       "      <td>i ordered these mainly because my wife was com...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223674</th>\n",
       "      <td>I don't understand if I got the wrong size or ...</td>\n",
       "      <td>2</td>\n",
       "      <td>i dont understand if i got the wrong size or i...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933420</th>\n",
       "      <td>Does not work.</td>\n",
       "      <td>2</td>\n",
       "      <td>does not work</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424735</th>\n",
       "      <td>This item is good if you don't mind it losing ...</td>\n",
       "      <td>2</td>\n",
       "      <td>this item is good if you dont mind it losing a...</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999395</th>\n",
       "      <td>I just bought a Compact System Camera and thou...</td>\n",
       "      <td>2</td>\n",
       "      <td>i just bought a compact system camera and thou...</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690540</th>\n",
       "      <td>I did not expect that these speakers would be ...</td>\n",
       "      <td>2</td>\n",
       "      <td>i did not expect that these speakers would be ...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58725</th>\n",
       "      <td>We returned them.  They are very heavy, you ca...</td>\n",
       "      <td>2</td>\n",
       "      <td>we returned them  they are very heavy you cant...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050653</th>\n",
       "      <td>I was searching for a laptop power adapter for...</td>\n",
       "      <td>1</td>\n",
       "      <td>i was searching for a laptop power adapter for...</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608126</th>\n",
       "      <td>The way of operating is not ideal, you need to...</td>\n",
       "      <td>2</td>\n",
       "      <td>the way of operating is not ideal you need to ...</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ReviewText  Rating  \\\n",
       "643867   I ordered these mainly because my wife was com...       1   \n",
       "1223674  I don't understand if I got the wrong size or ...       2   \n",
       "933420                                      Does not work.       2   \n",
       "1424735  This item is good if you don't mind it losing ...       2   \n",
       "999395   I just bought a Compact System Camera and thou...       2   \n",
       "690540   I did not expect that these speakers would be ...       2   \n",
       "58725    We returned them.  They are very heavy, you ca...       2   \n",
       "1050653  I was searching for a laptop power adapter for...       1   \n",
       "1608126  The way of operating is not ideal, you need to...       2   \n",
       "\n",
       "                                               CleanReview  WordCount  \\\n",
       "643867   i ordered these mainly because my wife was com...         84   \n",
       "1223674  i dont understand if i got the wrong size or i...         60   \n",
       "933420                                       does not work          3   \n",
       "1424735  this item is good if you dont mind it losing a...         74   \n",
       "999395   i just bought a compact system camera and thou...         76   \n",
       "690540   i did not expect that these speakers would be ...         65   \n",
       "58725    we returned them  they are very heavy you cant...         25   \n",
       "1050653  i was searching for a laptop power adapter for...         75   \n",
       "1608126  the way of operating is not ideal you need to ...         69   \n",
       "\n",
       "         Score_label  Predicted_Sentiment  \n",
       "643867             0                    1  \n",
       "1223674            0                    1  \n",
       "933420             0                    1  \n",
       "1424735            0                    1  \n",
       "999395             0                    1  \n",
       "690540             0                    1  \n",
       "58725              0                    1  \n",
       "1050653            0                    1  \n",
       "1608126            0                    1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############Review Text for Testing Results######################    \n",
    "#Take Reviews for test set\n",
    "start_idx = len(df_test) + len(val_x)\n",
    "end_idx = start_idx + len(test_pred_flat)\n",
    "ReviewsTest=ReviewsF.iloc[start_idx:end_idx]\n",
    "#Add Predicted Sentiment in a new column\n",
    "ReviewsTest['Predicted_Sentiment']= test_pred_flat\n",
    "\n",
    "#Examples of False Negative Results\n",
    "ReviewsTest[(ReviewsTest['Score_label'] == 1) & (ReviewsTest['Predicted_Sentiment'] == 0 )].iloc[1:10]    \n",
    "#Examples of False Positive Results\n",
    "ReviewsTest[(ReviewsTest['Score_label'] == 0) & (ReviewsTest['Predicted_Sentiment'] == 1 )].iloc[1:10]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
