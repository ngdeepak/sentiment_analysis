{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon Sentiment Analysis\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and preprocessing of the reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "dfTrain = pd.read_csv('data/train.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"')\n",
    "dfTrain = dfTrain[~dfTrain['ReviewText'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain['ReviewText'] = dfTrain['ReviewText'].apply(lambda x: str(x).lower())\\\n",
    "    .apply(lambda x: x.translate(x.maketrans('','', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfTrain[dfTrain['Rating'] == 1].sample(n = 50000, random_state = 15)\n",
    "df_train = df_train.append(dfTrain[dfTrain['Rating'] == 2].sample(n = 50000, random_state = 15))\n",
    "df_train = df_train.append(dfTrain[dfTrain['Rating'] == 3].sample(n = 50000, random_state = 15))\n",
    "df_train = df_train.append(dfTrain[dfTrain['Rating'] == 4].sample(n = 50000, random_state = 15))\n",
    "df_train = df_train.append(dfTrain[dfTrain['Rating'] == 5].sample(n = 50000, random_state = 15))\n",
    "df_train = df_train.copy()\n",
    "\n",
    "\n",
    "dftest = dfTrain.drop(labels = df_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term frequency-inverse document frequency (tf-idf) vectorizer parameters and then convert the review list into a tf-idf matrix.\n",
    "\n",
    "To get a Tf-idf matrix, first count word occurrences by reviewa. This is transformed into a document-term matrix (dtm). This is also just called a term frequency matrix.\n",
    "\n",
    "Then apply the term frequency-inverse document frequency weighting: words that occur frequently within a document but not frequently within the corpus receive a higher weighting as these words are assumed to contain more meaning in relation to the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_set1 = pd.read_csv('test1_generic_reviews.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"', index_col=0)\n",
    "df_validation_set2 = pd.read_csv('testB_dell_reviews.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['ReviewText'] = df_train['ReviewText'].str.split().apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df_train['ReviewText'] = df_train['ReviewText'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239969</th>\n",
       "      <td>eforcity laptop chill pad dual fan notebook co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267703</th>\n",
       "      <td>5 months drive trash connector part flimsy sna...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343683</th>\n",
       "      <td>tow cheap things work well enough low quality ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100239</th>\n",
       "      <td>got one wife worked week builtin software woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575687</th>\n",
       "      <td>13 years experience manager first found produc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ReviewText  Rating\n",
       "239969  eforcity laptop chill pad dual fan notebook co...       1\n",
       "267703  5 months drive trash connector part flimsy sna...       1\n",
       "343683  tow cheap things work well enough low quality ...       1\n",
       "100239  got one wife worked week builtin software woul...       1\n",
       "575687  13 years experience manager first found produc...       1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "# full_tf = tf.fit_transform(df_full['ReviewText'])\n",
    "dataf = tfidf.fit(df_train['ReviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in tqdm(df['ReviewText']):\n",
    "        \n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)\n",
    "\n",
    "#cleaned reviews for both train and test set retrieved\n",
    "train_sentences = clean_sentences(df_full)\n",
    "test_sentences = clean_sentences(df_test)\n",
    "print(len(train_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_traindata = dataf.transform(df_train['ReviewText'])\n",
    "X_test = dataf.transform(dftest['ReviewText'])\n",
    "y_train = df_train['Rating']\n",
    "y_test = dftest['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_traindata, y_train.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train: 0.595888\n",
      "Accuracy for test: 0.5425340442628187\n"
     ]
    }
   ],
   "source": [
    "train_predict = model.predict(X_traindata)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy for train: {metrics.accuracy_score(y_train, train_predict)}\")\n",
    "print(f\"Accuracy for text: {metrics.accuracy_score(y_test, test_predict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiments on Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 82 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_validation_set1 = pd.read_csv('test1_generic_reviews.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"', index_col=0)\n",
    "df_validation_set2 = pd.read_csv('testB_dell_reviews.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace null values with empty string, to garante test set is consistent with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_set1['ReviewText'].fillna('', inplace=True)\n",
    "df_validation_set2['ReviewText'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply tf_idf for both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation1 = dataf.transform(df_validation_set1['ReviewText'])\n",
    "X_validation2 = dataf.transform(df_validation_set2['ReviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1 = model.predict(X_validation1)\n",
    "predicted2 = model.predict(X_validation2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_validation1 = pd.DataFrame({'ReviewText': df_validation_set1['ReviewText'], 'PredictedRating': predicted1})\n",
    "pd_validation1.to_csv('validation7.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"')\n",
    "\n",
    "pd_validation2 = pd.DataFrame({'ReviewText': df_validation_set2['ReviewText'], 'PredictedRating': predicted2})\n",
    "pd_validation2.to_csv('validation8.csv', sep=\",\", encoding=\"utf-8\", quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
